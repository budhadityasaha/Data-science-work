{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation with RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description:**\n",
    "\n",
    "Using a given file having Shakespeare's text, build a character level RNN model that can generate text similar to given text\n",
    "\n",
    "**Responsibilities**\n",
    "\n",
    "• The file contains Shakespeare'text which is having (having more than 5 million chars). Encode the text for modelling.\n",
    "\n",
    "• Create batch to feed the data for a fixed length after converting the text vector into a stream of character indices. \n",
    "\n",
    "• Build RNN model that can generate text based on previos character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25249,
     "status": "ok",
     "timestamp": 1605499004078,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "L-Cl0zpoKfG9",
    "outputId": "8c363e75-863e-4f8a-ae3e-27cb3a038c58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2565,
     "status": "ok",
     "timestamp": 1605499014260,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "WBd69MDEm4rF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2750,
     "status": "ok",
     "timestamp": 1605358957969,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "kycWuRI9oaSP",
    "outputId": "d29a4db8-21f9-4173-ff25-d8c7b3782d65"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apj1Chkdm4rS"
   },
   "source": [
    "## Step 1: The Data\n",
    "\n",
    "You can grab any free text you want from here: https://www.gutenberg.org/\n",
    "\n",
    "We'll choose all of shakespeare's works (which we have already downloaded for you), mainly for two reasons:\n",
    "\n",
    "1. Its a large corpus of text, its usually recommended you have at least a source of 1 million characters total to get realistic text generation.\n",
    "\n",
    "2. It has a very distinctive style. Since the text data uses old style english and is formatted in the style of a stage play, it will be very obvious to us if the model is able to reproduce similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1109,
     "status": "ok",
     "timestamp": 1605499027774,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "pD_55cOxLkAb"
   },
   "outputs": [],
   "source": [
    "#path_to_file = '/content/drive/My Drive/Colab Notebooks/shakespeare.txt'\n",
    "path_to_file = 'C:\\\\Users\\\\budha\\\\TF_2_Notebooks_and_Data\\\\06-NLP-and-Text-Data\\\\shakespeare.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1342,
     "status": "ok",
     "timestamp": 1605499031336,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "aavnuByVymwK"
   },
   "outputs": [],
   "source": [
    "text = open(path_to_file, 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5445609"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "executionInfo": {
     "elapsed": 1046,
     "status": "ok",
     "timestamp": 1605499034586,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "qF23mcyZKNLN",
    "outputId": "1caf1c56-0c47-43b4-f019-72685f5ce11d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bu\""
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1065,
     "status": "ok",
     "timestamp": 1605499037257,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "Duhg9NrUymwO",
    "outputId": "72c83119-bed0-4686-8126-9d09d6a56f1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bu\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXUmR627m4rd"
   },
   "source": [
    "### Understanding unique characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1172,
     "status": "ok",
     "timestamp": 1605499041953,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "IlCgQBRVymwR",
    "outputId": "10a4008e-c73e-4787-cf65-c0ac0ffa6c99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '}']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(vocab)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1062,
     "status": "ok",
     "timestamp": 1605499044518,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "gzi_jRz6KNLV",
    "outputId": "df41b946-22aa-4957-a25b-e3375ffa4f5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNnrKn_lL-IJ"
   },
   "source": [
    "## Step 2: Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFjSVAlWzf-N"
   },
   "source": [
    "### Text Vectorization\n",
    "\n",
    "We know a neural network can't take in the raw string data, we need to assign numbers to each character. Let's create two dictionaries that can go from numeric index to character and character to numeric index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1323,
     "status": "ok",
     "timestamp": 1605499048674,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "okPqoiAmKNLY",
    "outputId": "5ed43672-4f4c-4070-e022-734fcbf53daf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '\\n')\n",
      "(1, ' ')\n",
      "(2, '!')\n",
      "(3, '\"')\n",
      "(4, '&')\n",
      "(5, \"'\")\n",
      "(6, '(')\n",
      "(7, ')')\n",
      "(8, ',')\n",
      "(9, '-')\n"
     ]
    }
   ],
   "source": [
    "for pair in enumerate(vocab[:10]):\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1046,
     "status": "ok",
     "timestamp": 1605499054190,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "IalZLbvOzf-F"
   },
   "outputs": [],
   "source": [
    "char_to_ind = {u:i for i, u in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1310,
     "status": "ok",
     "timestamp": 1605499059399,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "gmI5McEZKNLc",
    "outputId": "fbeae6a8-0bf7-4dfb-9d7f-de7b18dd2772"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '\"': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " '(': 6,\n",
       " ')': 7,\n",
       " ',': 8,\n",
       " '-': 9,\n",
       " '.': 10,\n",
       " '0': 11,\n",
       " '1': 12,\n",
       " '2': 13,\n",
       " '3': 14,\n",
       " '4': 15,\n",
       " '5': 16,\n",
       " '6': 17,\n",
       " '7': 18,\n",
       " '8': 19,\n",
       " '9': 20,\n",
       " ':': 21,\n",
       " ';': 22,\n",
       " '<': 23,\n",
       " '>': 24,\n",
       " '?': 25,\n",
       " 'A': 26,\n",
       " 'B': 27,\n",
       " 'C': 28,\n",
       " 'D': 29,\n",
       " 'E': 30,\n",
       " 'F': 31,\n",
       " 'G': 32,\n",
       " 'H': 33,\n",
       " 'I': 34,\n",
       " 'J': 35,\n",
       " 'K': 36,\n",
       " 'L': 37,\n",
       " 'M': 38,\n",
       " 'N': 39,\n",
       " 'O': 40,\n",
       " 'P': 41,\n",
       " 'Q': 42,\n",
       " 'R': 43,\n",
       " 'S': 44,\n",
       " 'T': 45,\n",
       " 'U': 46,\n",
       " 'V': 47,\n",
       " 'W': 48,\n",
       " 'X': 49,\n",
       " 'Y': 50,\n",
       " 'Z': 51,\n",
       " '[': 52,\n",
       " ']': 53,\n",
       " '_': 54,\n",
       " '`': 55,\n",
       " 'a': 56,\n",
       " 'b': 57,\n",
       " 'c': 58,\n",
       " 'd': 59,\n",
       " 'e': 60,\n",
       " 'f': 61,\n",
       " 'g': 62,\n",
       " 'h': 63,\n",
       " 'i': 64,\n",
       " 'j': 65,\n",
       " 'k': 66,\n",
       " 'l': 67,\n",
       " 'm': 68,\n",
       " 'n': 69,\n",
       " 'o': 70,\n",
       " 'p': 71,\n",
       " 'q': 72,\n",
       " 'r': 73,\n",
       " 's': 74,\n",
       " 't': 75,\n",
       " 'u': 76,\n",
       " 'v': 77,\n",
       " 'w': 78,\n",
       " 'x': 79,\n",
       " 'y': 80,\n",
       " 'z': 81,\n",
       " '|': 82,\n",
       " '}': 83}"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1055,
     "status": "ok",
     "timestamp": 1605499063886,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "6jg0B5BtKNLf",
    "outputId": "5469d831-298e-4b43-a376-563ddf154e0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ind['H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 1099,
     "status": "ok",
     "timestamp": 1605499067051,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "30ZYaWAOm4rt"
   },
   "outputs": [],
   "source": [
    "ind_to_char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1213,
     "status": "ok",
     "timestamp": 1605499074633,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "_6JPOWwJm4rz",
    "outputId": "603f6053-0d50-49d5-878f-b6202cc66d26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1',\n",
       "       '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?',\n",
       "       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
       "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
       "       '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i',\n",
       "       'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v',\n",
       "       'w', 'x', 'y', 'z', '|', '}'], dtype='<U1')"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1292,
     "status": "ok",
     "timestamp": 1605499079712,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "2L6r8MTuKNLl",
    "outputId": "cb442b3b-3283-4176-fdc5-3a5ef966bf63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ind_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1086,
     "status": "ok",
     "timestamp": 1605499123995,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "EVBtgpYgKNLn",
    "outputId": "50648e2f-4dd3-41fa-b912-31a8eff29e1e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'H'"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_char[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rKWIu-e33cBM"
   },
   "outputs": [],
   "source": [
    "#list(char_to_ind[c] for c in text)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 1859,
     "status": "ok",
     "timestamp": 1605499087684,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "3fhOqV0lm4r2"
   },
   "outputs": [],
   "source": [
    "encoded_text = np.array([char_to_ind[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1029,
     "status": "ok",
     "timestamp": 1605499095449,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "axOX7rFom4r5",
    "outputId": "039e56d0-91cc-4914-e122-344f8e389e33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  1, ..., 30, 39, 29])"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1068,
     "status": "ok",
     "timestamp": 1605499129952,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "RspNKUkwKNLt",
    "outputId": "7a674ae9-da5d-4d13-fa05-2aae3fb951a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5445609,)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZfqhkYCymwX"
   },
   "source": [
    "We now have a mapping we can use to go back and forth from characters to numerics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "executionInfo": {
     "elapsed": 1061,
     "status": "ok",
     "timestamp": 1605499133370,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "tFs1Uza-m4r9",
    "outputId": "9ec4756d-2dd8-4f8f-9226-fc8e21a243e9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bu\""
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = text[:500]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1320,
     "status": "ok",
     "timestamp": 1605499135894,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "gIqUCK5Am4sB",
    "outputId": "c194f99a-4e44-4059-9908-65a93c3aa167"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1, 12,  0,  1,  1, 31, 73, 70, 68,  1, 61, 56, 64,\n",
       "       73, 60, 74, 75,  1, 58, 73, 60, 56, 75, 76, 73, 60, 74,  1, 78, 60,\n",
       "        1, 59, 60, 74, 64, 73, 60,  1, 64, 69, 58, 73, 60, 56, 74, 60,  8,\n",
       "        0,  1,  1, 45, 63, 56, 75,  1, 75, 63, 60, 73, 60, 57, 80,  1, 57,\n",
       "       60, 56, 76, 75, 80,  5, 74,  1, 73, 70, 74, 60,  1, 68, 64, 62, 63,\n",
       "       75,  1, 69, 60, 77, 60, 73,  1, 59, 64, 60,  8,  0,  1,  1, 27, 76,\n",
       "       75,  1, 56, 74,  1, 75, 63, 60,  1, 73, 64, 71, 60, 73,  1, 74, 63,\n",
       "       70, 76, 67, 59,  1, 57, 80,  1, 75, 64, 68, 60,  1, 59, 60, 58, 60,\n",
       "       56, 74, 60,  8,  0,  1,  1, 33, 64, 74,  1, 75, 60, 69, 59, 60, 73,\n",
       "        1, 63, 60, 64, 73,  1, 68, 64, 62, 63, 75,  1, 57, 60, 56, 73,  1,\n",
       "       63, 64, 74,  1, 68, 60, 68, 70, 73, 80, 21,  0,  1,  1, 27, 76, 75,\n",
       "        1, 75, 63, 70, 76,  1, 58, 70, 69, 75, 73, 56, 58, 75, 60, 59,  1,\n",
       "       75, 70,  1, 75, 63, 64, 69, 60,  1, 70, 78, 69,  1, 57, 73, 64, 62,\n",
       "       63, 75,  1, 60, 80, 60, 74,  8,  0,  1,  1, 31, 60, 60, 59,  5, 74,\n",
       "       75,  1, 75, 63, 80,  1, 67, 64, 62, 63, 75,  5, 74,  1, 61, 67, 56,\n",
       "       68, 60,  1, 78, 64, 75, 63,  1, 74, 60, 67, 61,  9, 74, 76, 57, 74,\n",
       "       75, 56, 69, 75, 64, 56, 67,  1, 61, 76, 60, 67,  8,  0,  1,  1, 38,\n",
       "       56, 66, 64, 69, 62,  1, 56,  1, 61, 56, 68, 64, 69, 60,  1, 78, 63,\n",
       "       60, 73, 60,  1, 56, 57, 76, 69, 59, 56, 69, 58, 60,  1, 67, 64, 60,\n",
       "       74,  8,  0,  1,  1, 45, 63, 80,  1, 74, 60, 67, 61,  1, 75, 63, 80,\n",
       "        1, 61, 70, 60,  8,  1, 75, 70,  1, 75, 63, 80,  1, 74, 78, 60, 60,\n",
       "       75,  1, 74, 60, 67, 61,  1, 75, 70, 70,  1, 58, 73, 76, 60, 67, 21,\n",
       "        0,  1,  1, 45, 63, 70, 76,  1, 75, 63, 56, 75,  1, 56, 73, 75,  1,\n",
       "       69, 70, 78,  1, 75, 63, 60,  1, 78, 70, 73, 67, 59,  5, 74,  1, 61,\n",
       "       73, 60, 74, 63,  1, 70, 73, 69, 56, 68, 60, 69, 75,  8,  0,  1,  1,\n",
       "       26, 69, 59,  1, 70, 69, 67, 80,  1, 63, 60, 73, 56, 67, 59,  1, 75,\n",
       "       70,  1, 75, 63, 60,  1, 62, 56, 76, 59, 80,  1, 74, 71, 73, 64, 69,\n",
       "       62,  8,  0,  1,  1, 48, 64, 75, 63, 64, 69,  1, 75, 63, 64, 69, 60,\n",
       "        1, 70, 78, 69,  1, 57, 76])"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbmsf23Bymwe"
   },
   "source": [
    "## Step 3: Creating Batches\n",
    "\n",
    "Overall what we are trying to achieve is to have the model predict the next highest probability character given a historical sequence of characters. Its up to us (the user) to choose how long that historic sequence. Too short a sequence and we don't have enough information (e.g. given the letter \"a\" , what is the next character) , too long a sequence and training will take too long and most likely overfit to sequence characters that are irrelevant to characters farther out. While there is no correct sequence length choice, you should consider the text itself, how long normal phrases are in it, and a reasonable idea of what characters/words are relevant to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1095,
     "status": "ok",
     "timestamp": 1605499140934,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "pAvUYFk7m4sF",
    "outputId": "5e092e5e-96bf-415b-fa4e-9557da6a4ebd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bu\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 1384,
     "status": "ok",
     "timestamp": 1605499144825,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "D45OYgOfm4sJ"
   },
   "outputs": [],
   "source": [
    "line = \"From fairest creatures we desire increase\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1065,
     "status": "ok",
     "timestamp": 1605499146522,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "7dKiEVN8m4sL",
    "outputId": "96bc361b-fab7-4d5f-bf35-448837e32d39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 1345,
     "status": "ok",
     "timestamp": 1605499150309,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "olX67f6-m4sP"
   },
   "outputs": [],
   "source": [
    "part_stanza = '''From fairest creatures we desire increase,\n",
    "  That thereby beauty's rose might never die,\n",
    "  But as the riper should by time decease,'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1322,
     "status": "ok",
     "timestamp": 1605499152646,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "qal7MQnqm4sQ",
    "outputId": "532bc7a8-b2fb-419e-af6a-c37d03a2dc39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(part_stanza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgsVvVxnymwf"
   },
   "source": [
    "### Training Sequences\n",
    "\n",
    "The actual text data will be the text sequence shifted one character forward. For example:\n",
    "\n",
    "Sequence In: \"Hello my nam\"\n",
    "Sequence Out: \"ello my name\"\n",
    "\n",
    "\n",
    "We can use the `tf.data.Dataset.from_tensor_slices` function to convert a text vector into a stream of character indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 1321,
     "status": "ok",
     "timestamp": 1605499156237,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "0UHJDA39zf-O"
   },
   "outputs": [],
   "source": [
    "seq_len = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 1103,
     "status": "ok",
     "timestamp": 1605499158401,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "7VRSK4cOm4sZ"
   },
   "outputs": [],
   "source": [
    "total_num_seq = len(text)//(seq_len+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1042,
     "status": "ok",
     "timestamp": 1605499161103,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "xtW0jbbvm4sc",
    "outputId": "74c10416-5dc8-4bdc-a828-2b05e2d66bf7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45005"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_num_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6560,
     "status": "ok",
     "timestamp": 1605499169722,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "ciatnowvm4se",
    "outputId": "95aa6bf2-e7df-46a6-8e9f-9ff80fa0f72a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "1\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "F\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "f\n",
      "a\n",
      "i\n",
      "r\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "c\n",
      "r\n",
      "e\n",
      "a\n",
      "t\n",
      "u\n",
      "r\n",
      "e\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      "s\n",
      "i\n",
      "r\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "c\n",
      "r\n",
      "e\n",
      "a\n",
      "s\n",
      "e\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "T\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      "b\n",
      "y\n",
      " \n",
      "b\n",
      "e\n",
      "a\n",
      "u\n",
      "t\n",
      "y\n",
      "'\n",
      "s\n",
      " \n",
      "r\n",
      "o\n",
      "s\n",
      "e\n",
      " \n",
      "m\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      " \n",
      "n\n",
      "e\n",
      "v\n",
      "e\n",
      "r\n",
      " \n",
      "d\n",
      "i\n",
      "e\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "B\n",
      "u\n",
      "t\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "r\n",
      "i\n",
      "p\n",
      "e\n",
      "r\n",
      " \n",
      "s\n",
      "h\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "t\n",
      "i\n",
      "m\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      "c\n",
      "e\n",
      "a\n",
      "s\n",
      "e\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "H\n",
      "i\n",
      "s\n",
      " \n",
      "t\n",
      "e\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      " \n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      " \n",
      "m\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      " \n",
      "b\n",
      "e\n",
      "a\n",
      "r\n",
      " \n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "m\n",
      "e\n",
      "m\n",
      "o\n",
      "r\n",
      "y\n",
      ":\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "B\n",
      "u\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "o\n",
      "u\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "b\n",
      "r\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      " \n",
      "e\n",
      "y\n",
      "e\n",
      "s\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "F\n",
      "e\n",
      "e\n",
      "d\n",
      "'\n",
      "s\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "y\n",
      " \n",
      "l\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      "'\n",
      "s\n",
      " \n",
      "f\n",
      "l\n",
      "a\n",
      "m\n",
      "e\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      "-\n",
      "s\n",
      "u\n",
      "b\n",
      "s\n",
      "t\n",
      "a\n",
      "n\n",
      "t\n",
      "i\n",
      "a\n",
      "l\n",
      " \n",
      "f\n",
      "u\n",
      "e\n",
      "l\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "M\n",
      "a\n",
      "k\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      " \n",
      "f\n",
      "a\n",
      "m\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "a\n",
      "b\n",
      "u\n",
      "n\n",
      "d\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "l\n",
      "i\n",
      "e\n",
      "s\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "T\n",
      "h\n",
      "y\n",
      " \n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "y\n",
      " \n",
      "f\n",
      "o\n",
      "e\n",
      ",\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "y\n",
      " \n",
      "s\n",
      "w\n",
      "e\n",
      "e\n",
      "t\n",
      " \n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      " \n",
      "t\n",
      "o\n",
      "o\n",
      " \n",
      "c\n",
      "r\n",
      "u\n",
      "e\n",
      "l\n",
      ":\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "T\n",
      "h\n",
      "o\n",
      "u\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "a\n",
      "r\n",
      "t\n",
      " \n",
      "n\n",
      "o\n",
      "w\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "l\n",
      "d\n",
      "'\n",
      "s\n",
      " \n",
      "f\n",
      "r\n",
      "e\n",
      "s\n",
      "h\n",
      " \n",
      "o\n",
      "r\n",
      "n\n",
      "a\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "A\n",
      "n\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      "l\n",
      "y\n",
      " \n",
      "h\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "g\n",
      "a\n",
      "u\n",
      "d\n",
      "y\n",
      " \n",
      "s\n",
      "p\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "W\n",
      "i\n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "b\n",
      "u\n"
     ]
    }
   ],
   "source": [
    "# Create Training Sequences\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
    "\n",
    "for i in char_dataset.take(500):\n",
    "     print(ind_to_char[i.numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZSYAcQV8OGP"
   },
   "source": [
    "The **batch** method converts these individual character calls into sequences we can feed in as a batch. We use seq_len+1 because of zero indexing. Here is what drop_remainder means:\n",
    "\n",
    "drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
    "    whether the last batch should be dropped in the case it has fewer than\n",
    "    `batch_size` elements; the default behavior is not to drop the smaller\n",
    "    batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 1063,
     "status": "ok",
     "timestamp": 1605499190107,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "l4hkDU3i7ozi"
   },
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_len+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbLcIPBj_mWZ"
   },
   "source": [
    "Now that we have our sequences, we will perform the following steps for each one to create our target text sequences:\n",
    "\n",
    "1. Grab the input text sequence\n",
    "2. Assign the target text sequence as the input text sequence shifted by one step forward\n",
    "3. Group them together as a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 1291,
     "status": "ok",
     "timestamp": 1605499194151,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "9NGu-FkO_kYU"
   },
   "outputs": [],
   "source": [
    "def create_seq_targets(seq):\n",
    "    input_txt = seq[:-1]   #Hello my nam\n",
    "    target_txt = seq[1:]   #ello my name\n",
    "    return input_txt, target_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 1030,
     "status": "ok",
     "timestamp": 1605499196464,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "HszljTg8m4so"
   },
   "outputs": [],
   "source": [
    "dataset = sequences.map(create_seq_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1095,
     "status": "ok",
     "timestamp": 1605499254431,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "VLLEKzVLKNMO",
    "outputId": "d19b0e9a-b0ef-41ab-95c9-0dbb7d0c708b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((120,), (120,)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1105,
     "status": "ok",
     "timestamp": 1605499256723,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "JkPa7AMrm4sq",
    "outputId": "0a01b76f-9528-40be-f0ae-cfdf3fc7ea7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
      "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
      "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
      " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
      " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But\n",
      "\n",
      "\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
      "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
      " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
      " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
      "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But \n"
     ]
    }
   ],
   "source": [
    "for input_txt, target_txt in  dataset.take(1):\n",
    "    print(input_txt.numpy())\n",
    "    print(''.join(ind_to_char[input_txt.numpy()]))\n",
    "    print('\\n')\n",
    "    print(target_txt.numpy())\n",
    "    # There is an extra whitespace!\n",
    "    print(''.join(ind_to_char[target_txt.numpy()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJdfPmdqzf-R"
   },
   "source": [
    "### Generating training batches\n",
    "\n",
    "Now that we have the actual sequences, we will create the batches, we want to shuffle these sequences into a random order, so the model doesn't overfit to any section of the text, but can instead generate characters given any seed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 1096,
     "status": "ok",
     "timestamp": 1605499278980,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "p2pGotuNzf-S"
   },
   "outputs": [],
   "source": [
    "# Batch size\n",
    "batch_size = 128\n",
    "\n",
    "# Buffer size to shuffle the dataset so it doesn't attempt to shuffle\n",
    "# the entire sequence in memory. Instead, it maintains a buffer in which it shuffles elements\n",
    "buffer_size = 10000\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1126,
     "status": "ok",
     "timestamp": 1605499281269,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "gmcCALymm4su",
    "outputId": "2e45cff5-e9c2-405f-f5fc-2255ca899888"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((128, 120), (128, 120)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6oUuElIMgVx"
   },
   "source": [
    "## Step 4: Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8gPwEjRzf-Z"
   },
   "source": [
    "We will use an LSTM based model with a few extra features, including an embedding layer to start off with and **two** LSTM layers. We based this model architecture off the [DeepMoji](https://deepmoji.mit.edu/) and the original source code can be found [here](https://github.com/bfelbo/DeepMoji).\n",
    "\n",
    "The embedding layer will serve as the input layer, which essentially creates a lookup table that maps the numbers indices of each character to a vector with \"embedding dim\" number of dimensions. As you can imagine, the larger this embedding size, the more complex the training. This is similar to the idea behind word2vec, where words are mapped to some n-dimensional space. Embedding before feeding straight into the LSTM usually leads to more realisitic results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 654,
     "status": "ok",
     "timestamp": 1605499285092,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "r9ghKo8qKNMZ",
    "outputId": "1457678d-abd5-4ca2-af9f-3760d97ddd1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 1082,
     "status": "ok",
     "timestamp": 1605499288507,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "zHT8cLh7EAsg"
   },
   "outputs": [],
   "source": [
    "# The embedding dimension\n",
    "embed_dim = 64\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_neurons = 1026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Atb060h5m4s0"
   },
   "source": [
    "Now let's create a function that easily adapts to different variables as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 1098,
     "status": "ok",
     "timestamp": 1605499291395,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "YeRlEXgym4s1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcMbIy-xj-w-"
   },
   "source": [
    "### Setting up Loss Function\n",
    "\n",
    "For our loss we will use sparse categorical crossentropy, which we can import from Keras. We will also set this as logits=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 1303,
     "status": "ok",
     "timestamp": 1605499295088,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "VoFVGKlNkJfW"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1084,
     "status": "ok",
     "timestamp": 1605359487113,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "sblCzZoslZKH",
    "outputId": "b8a7677f-5dc1-4681-8d1a-11653a8e34fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function sparse_categorical_crossentropy in module tensorflow.python.keras.losses:\n",
      "\n",
      "sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1)\n",
      "    Computes the sparse categorical crossentropy loss.\n",
      "    \n",
      "    Standalone usage:\n",
      "    \n",
      "    >>> y_true = [1, 2]\n",
      "    >>> y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
      "    >>> loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
      "    >>> assert loss.shape == (2,)\n",
      "    >>> loss.numpy()\n",
      "    array([0.0513, 2.303], dtype=float32)\n",
      "    \n",
      "    Args:\n",
      "      y_true: Ground truth values.\n",
      "      y_pred: The predicted values.\n",
      "      from_logits: Whether `y_pred` is expected to be a logits tensor. By default,\n",
      "        we assume that `y_pred` encodes a probability distribution.\n",
      "      axis: (Optional) Defaults to -1. The dimension along which the entropy is\n",
      "        computed.\n",
      "    \n",
      "    Returns:\n",
      "      Sparse categorical crossentropy loss value.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sparse_categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5N4Qxbij5gY"
   },
   "source": [
    "https://datascience.stackexchange.com/questions/41921/sparse-categorical-crossentropy-vs-categorical-crossentropy-keras-accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 1207,
     "status": "ok",
     "timestamp": 1605499299967,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "FrOOK61Olm1C"
   },
   "outputs": [],
   "source": [
    "def sparse_cat_loss(y_true,y_pred):\n",
    "    return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 1075,
     "status": "ok",
     "timestamp": 1605499302109,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "MtCrdfzEI2N0"
   },
   "outputs": [],
   "source": [
    "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embed_dim,batch_input_shape=[batch_size, None]))\n",
    "    model.add(GRU(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
    "    # Final Dense Layer to Predict\n",
    "    model.add(Dense(vocab_size))\n",
    "    model.compile(optimizer='adam', loss=sparse_cat_loss) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 1023,
     "status": "ok",
     "timestamp": 1605499311150,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "wwsrpOik5zhv"
   },
   "outputs": [],
   "source": [
    "model = create_model(\n",
    "  vocab_size = vocab_size,\n",
    "  embed_dim=embed_dim,\n",
    "  rnn_neurons=rnn_neurons,\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1048,
     "status": "ok",
     "timestamp": 1605499313840,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "liXuTFYMm4s6",
    "outputId": "d430cc0e-484c-4550-98b1-795a29bd22bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (128, None, 64)           5376      \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (128, None, 1026)         3361176   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (128, None, 84)           86268     \n",
      "=================================================================\n",
      "Total params: 3,452,820\n",
      "Trainable params: 3,452,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJL0Q0YPY6Ee"
   },
   "source": [
    "## Step 5: Training the model\n",
    "\n",
    "Let's make sure everything is ok with our model before we spend too much time training! Let's pass in a batch to confirm the model currently predicts random characters without any training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8468,
     "status": "ok",
     "timestamp": 1605499327090,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "A4ygvfHn-wan",
    "outputId": "d11cab16-691c-4152-a647-bf73cfbd9d1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 120, 84)  <=== (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "\n",
    "  # Predict off some random batch\n",
    "  example_batch_predictions = model(input_example_batch)\n",
    "\n",
    "  # Display the dimensions of the predictions\n",
    "  print(example_batch_predictions.shape, \" <=== (batch_size, sequence_length, vocab_size)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1605499330452,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "yHZ6hTBSKNMy",
    "outputId": "776039ed-e5f8-4694-bee5-c01d5a1303f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128, 120, 84])"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1109,
     "status": "ok",
     "timestamp": 1605499333264,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "5ld8z3LPBAuv",
    "outputId": "4518ed4d-4834-4cf5-ab5c-57b03c0896de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128, 120, 84), dtype=float32, numpy=\n",
       "array([[[ 1.1842721e-03,  8.5755391e-04, -3.3618039e-03, ...,\n",
       "          2.5133332e-03,  1.1244775e-02,  6.4818356e-03],\n",
       "        [ 2.6369819e-03,  2.3921486e-04, -4.7738366e-03, ...,\n",
       "          3.9427388e-03,  1.6698815e-02,  9.1727991e-03],\n",
       "        [ 6.8185516e-03, -2.3383624e-04, -2.2867264e-03, ...,\n",
       "         -2.1889564e-03,  1.4886921e-02,  5.2534067e-03],\n",
       "        ...,\n",
       "        [ 2.2127554e-03, -7.8938631e-03, -1.3028354e-03, ...,\n",
       "         -4.0365704e-03, -4.0667886e-03,  4.7552469e-04],\n",
       "        [-1.0654639e-03, -4.4856570e-03, -2.8850790e-03, ...,\n",
       "          2.2293692e-03,  2.3970872e-03, -1.1864515e-03],\n",
       "        [ 3.7032717e-03, -2.5941161e-03,  1.4226725e-03, ...,\n",
       "         -4.1372771e-03, -1.0428395e-03,  7.6733567e-03]],\n",
       "\n",
       "       [[-5.7380046e-03, -1.0588712e-03, -1.2653979e-03, ...,\n",
       "         -9.8620588e-04,  7.8294156e-03,  1.0825766e-03],\n",
       "        [-2.4442561e-06, -1.6129082e-03,  2.7426914e-03, ...,\n",
       "         -4.5443452e-03,  1.9961391e-03,  7.6180585e-03],\n",
       "        [ 5.1986352e-03, -4.8317979e-03,  5.4405355e-03, ...,\n",
       "         -2.7314643e-04,  2.5717127e-03,  1.6297353e-04],\n",
       "        ...,\n",
       "        [ 2.5663590e-03, -1.2201020e-03,  2.7302783e-03, ...,\n",
       "          1.6010199e-03,  7.6411115e-03, -4.2588272e-04],\n",
       "        [ 3.2101911e-03, -5.3715575e-03, -5.8432305e-03, ...,\n",
       "          9.4102463e-05,  9.5532089e-03, -3.5195407e-03],\n",
       "        [ 2.5928998e-03, -2.9535801e-03, -6.0114209e-03, ...,\n",
       "          2.5467360e-03,  1.5980557e-02,  5.7880664e-03]],\n",
       "\n",
       "       [[ 1.1842721e-03,  8.5755391e-04, -3.3618039e-03, ...,\n",
       "          2.5133332e-03,  1.1244775e-02,  6.4818356e-03],\n",
       "        [ 7.9514197e-05,  1.8203686e-03, -2.6815776e-03, ...,\n",
       "          4.7019823e-03,  7.1361647e-03,  1.2994170e-03],\n",
       "        [ 8.6161215e-04,  1.1736229e-03, -5.3832941e-03, ...,\n",
       "          4.3205200e-03,  1.4995646e-02,  7.8050816e-03],\n",
       "        ...,\n",
       "        [-1.9147992e-06, -1.9082516e-03,  2.9286009e-03, ...,\n",
       "         -3.8576333e-03,  3.1636558e-03,  6.8384903e-03],\n",
       "        [-1.0822467e-03,  1.1506663e-03,  2.9259245e-05, ...,\n",
       "          1.4505202e-03,  2.8867186e-03,  3.3847471e-03],\n",
       "        [ 9.0131322e-03,  1.6203206e-03, -1.7049080e-03, ...,\n",
       "          2.7167378e-03,  1.1275831e-03,  3.7727971e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.7091352e-03, -3.9477553e-03, -7.5343391e-03, ...,\n",
       "         -1.3185096e-03,  4.9339421e-03, -2.9062696e-03],\n",
       "        [ 3.4113829e-03, -1.0095481e-03, -7.6987986e-03, ...,\n",
       "         -5.9435288e-03,  6.3561602e-03,  2.5089497e-03],\n",
       "        [ 1.5086273e-03, -6.0745096e-04, -7.0803617e-03, ...,\n",
       "         -2.1034058e-03,  1.5556492e-02,  7.9417992e-03],\n",
       "        ...,\n",
       "        [ 5.0767092e-03,  5.4429630e-03, -3.1554715e-03, ...,\n",
       "          5.9960452e-03,  5.3199278e-03,  5.6296764e-03],\n",
       "        [ 1.9964543e-03, -2.6637660e-03, -6.6311564e-03, ...,\n",
       "          6.6291774e-05,  3.2198308e-03,  2.2605532e-03],\n",
       "        [-5.2440015e-04,  8.6178392e-04, -4.8914072e-03, ...,\n",
       "          1.7657806e-03,  3.6769970e-03,  4.4365264e-03]],\n",
       "\n",
       "       [[-3.8890571e-03,  2.3744621e-03,  1.4860330e-03, ...,\n",
       "         -1.0346439e-03, -1.8056140e-03,  9.9107798e-04],\n",
       "        [-2.5964912e-04, -3.5295526e-03, -7.3732915e-03, ...,\n",
       "         -3.6965206e-03,  3.1825406e-03, -1.5024026e-03],\n",
       "        [ 9.6777864e-03, -1.6988399e-03, -4.1374229e-03, ...,\n",
       "         -8.1652903e-04,  1.3941177e-04,  1.6773716e-03],\n",
       "        ...,\n",
       "        [ 2.2077439e-03, -1.8683586e-03, -6.2752152e-03, ...,\n",
       "          1.7651562e-03,  1.4312346e-02,  5.4620993e-03],\n",
       "        [ 7.9877442e-03, -5.8307243e-04,  8.4248930e-03, ...,\n",
       "         -1.1868462e-03, -2.9093777e-03, -4.6427781e-04],\n",
       "        [ 1.9226754e-03, -1.9757524e-03,  1.2290737e-03, ...,\n",
       "          2.9724550e-03,  4.1342853e-03, -8.7289041e-04]],\n",
       "\n",
       "       [[-1.3642552e-03,  2.4425955e-03, -1.2703373e-03, ...,\n",
       "          3.2535116e-03,  1.7202967e-03, -1.3937518e-03],\n",
       "        [-1.1449419e-03,  1.4118658e-03,  2.8712947e-03, ...,\n",
       "          6.6044065e-04,  1.0558855e-03, -2.4832436e-03],\n",
       "        [-5.2328864e-03,  3.0113417e-03,  2.5113854e-03, ...,\n",
       "         -7.8183546e-04, -2.9572286e-04, -4.7416508e-04],\n",
       "        ...,\n",
       "        [ 4.3150093e-03, -5.7479437e-04, -5.9658736e-03, ...,\n",
       "          4.5123980e-03,  2.0398494e-02,  1.2137612e-02],\n",
       "        [ 4.5992071e-03,  1.6285188e-03, -2.4818366e-03, ...,\n",
       "         -1.3063506e-03,  7.7608535e-03,  9.5972726e-03],\n",
       "        [ 4.3911743e-03, -1.1536386e-04, -2.1535519e-03, ...,\n",
       "         -3.0221967e-03,  4.0844288e-03,  4.3815384e-03]]], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1083,
     "status": "ok",
     "timestamp": 1605499342160,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "F4TxP7IrLz_z",
    "outputId": "6410357f-a3cd-4ea4-9e60-7fb958493d54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([120, 84])"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 1024,
     "status": "ok",
     "timestamp": 1605499344331,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "_achqjT-BGyY"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1390,
     "status": "ok",
     "timestamp": 1605499347822,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "xWrPFk2nBJX4",
    "outputId": "78ef4484-669c-46bb-be5d-83eef5336fcf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(120, 1), dtype=int64, numpy=\n",
       "array([[21],\n",
       "       [47],\n",
       "       [17],\n",
       "       [29],\n",
       "       [62],\n",
       "       [66],\n",
       "       [83],\n",
       "       [21],\n",
       "       [70],\n",
       "       [72],\n",
       "       [46],\n",
       "       [31],\n",
       "       [36],\n",
       "       [24],\n",
       "       [ 0],\n",
       "       [75],\n",
       "       [79],\n",
       "       [73],\n",
       "       [13],\n",
       "       [70],\n",
       "       [77],\n",
       "       [69],\n",
       "       [26],\n",
       "       [56],\n",
       "       [47],\n",
       "       [77],\n",
       "       [78],\n",
       "       [ 0],\n",
       "       [59],\n",
       "       [51],\n",
       "       [25],\n",
       "       [ 2],\n",
       "       [55],\n",
       "       [69],\n",
       "       [ 7],\n",
       "       [18],\n",
       "       [34],\n",
       "       [24],\n",
       "       [22],\n",
       "       [10],\n",
       "       [29],\n",
       "       [ 4],\n",
       "       [29],\n",
       "       [ 0],\n",
       "       [25],\n",
       "       [45],\n",
       "       [24],\n",
       "       [33],\n",
       "       [ 5],\n",
       "       [28],\n",
       "       [34],\n",
       "       [23],\n",
       "       [46],\n",
       "       [76],\n",
       "       [42],\n",
       "       [27],\n",
       "       [69],\n",
       "       [ 4],\n",
       "       [80],\n",
       "       [78],\n",
       "       [ 3],\n",
       "       [16],\n",
       "       [28],\n",
       "       [37],\n",
       "       [21],\n",
       "       [35],\n",
       "       [32],\n",
       "       [70],\n",
       "       [14],\n",
       "       [83],\n",
       "       [26],\n",
       "       [47],\n",
       "       [53],\n",
       "       [61],\n",
       "       [15],\n",
       "       [78],\n",
       "       [12],\n",
       "       [79],\n",
       "       [ 2],\n",
       "       [68],\n",
       "       [81],\n",
       "       [16],\n",
       "       [57],\n",
       "       [11],\n",
       "       [22],\n",
       "       [50],\n",
       "       [47],\n",
       "       [24],\n",
       "       [41],\n",
       "       [50],\n",
       "       [29],\n",
       "       [20],\n",
       "       [68],\n",
       "       [35],\n",
       "       [56],\n",
       "       [73],\n",
       "       [54],\n",
       "       [12],\n",
       "       [53],\n",
       "       [35],\n",
       "       [76],\n",
       "       [79],\n",
       "       [43],\n",
       "       [72],\n",
       "       [60],\n",
       "       [18],\n",
       "       [79],\n",
       "       [ 9],\n",
       "       [ 7],\n",
       "       [25],\n",
       "       [78],\n",
       "       [41],\n",
       "       [83],\n",
       "       [ 2],\n",
       "       [70],\n",
       "       [10],\n",
       "       [39],\n",
       "       [21],\n",
       "       [61],\n",
       "       [ 3]])>"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 1121,
     "status": "ok",
     "timestamp": 1605499355610,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "Wi80PQVtBLqj"
   },
   "outputs": [],
   "source": [
    "# Reformat to not be a lists of lists\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1079,
     "status": "ok",
     "timestamp": 1605499358727,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "4qYkIg00-wjq",
    "outputId": "d9fa228a-6401-4349-c9f8-64bf0c802fec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 47, 17, 29, 62, 66, 83, 21, 70, 72, 46, 31, 36, 24,  0, 75, 79,\n",
       "       73, 13, 70, 77, 69, 26, 56, 47, 77, 78,  0, 59, 51, 25,  2, 55, 69,\n",
       "        7, 18, 34, 24, 22, 10, 29,  4, 29,  0, 25, 45, 24, 33,  5, 28, 34,\n",
       "       23, 46, 76, 42, 27, 69,  4, 80, 78,  3, 16, 28, 37, 21, 35, 32, 70,\n",
       "       14, 83, 26, 47, 53, 61, 15, 78, 12, 79,  2, 68, 81, 16, 57, 11, 22,\n",
       "       50, 47, 24, 41, 50, 29, 20, 68, 35, 56, 73, 54, 12, 53, 35, 76, 79,\n",
       "       43, 72, 60, 18, 79,  9,  7, 25, 78, 41, 83,  2, 70, 10, 39, 21, 61,\n",
       "        3])"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1075,
     "status": "ok",
     "timestamp": 1605499363542,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "IpqZUY0kQr9y",
    "outputId": "d098ca37-2ae5-4bd8-a9d5-652b4b0e8268"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([':', 'V', '6', 'D', 'g', 'k', '}', ':', 'o', 'q', 'U', 'F', 'K',\n",
       "       '>', '\\n', 't', 'x', 'r', '2', 'o', 'v', 'n', 'A', 'a', 'V', 'v',\n",
       "       'w', '\\n', 'd', 'Z', '?', '!', '`', 'n', ')', '7', 'I', '>', ';',\n",
       "       '.', 'D', '&', 'D', '\\n', '?', 'T', '>', 'H', \"'\", 'C', 'I', '<',\n",
       "       'U', 'u', 'Q', 'B', 'n', '&', 'y', 'w', '\"', '5', 'C', 'L', ':',\n",
       "       'J', 'G', 'o', '3', '}', 'A', 'V', ']', 'f', '4', 'w', '1', 'x',\n",
       "       '!', 'm', 'z', '5', 'b', '0', ';', 'Y', 'V', '>', 'P', 'Y', 'D',\n",
       "       '9', 'm', 'J', 'a', 'r', '_', '1', ']', 'J', 'u', 'x', 'R', 'q',\n",
       "       'e', '7', 'x', '-', ')', '?', 'w', 'P', '}', '!', 'o', '.', 'N',\n",
       "       ':', 'f', '\"'], dtype='<U1')"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_char[sampled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1059,
     "status": "ok",
     "timestamp": 1605499369176,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "H9-P_XqQ_7wY",
    "outputId": "0bbc7dbb-2c6d-4367-9d68-6334a385e9b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the input seq: \n",
      "\n",
      "  TOUCHSTONE. 'Thank God.' A good answer.\n",
      "    Art rich?\n",
      "  WILLIAM. Faith, sir, so so.\n",
      "  TOUCHSTONE. 'So so' is good, ver\n",
      "\n",
      "\n",
      "Next Char Predictions: \n",
      "\n",
      ":V6Dgk}:oqUFK>\n",
      "txr2ovnAaVvw\n",
      "dZ?!`n)7I>;.D&D\n",
      "?T>H'CI<UuQBn&yw\"5CL:JGo3}AV]f4w1x!mz5b0;YV>PYD9mJar_1]JuxRqe7x-)?wP}!o.N:f\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Given the input seq: \\n\")\n",
    "print(\"\".join(ind_to_char[input_example_batch[0]]))\n",
    "print('\\n')\n",
    "print(\"Next Char Predictions: \\n\")\n",
    "print(\"\".join(ind_to_char[sampled_indices ]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAOE4rzuBh7f"
   },
   "source": [
    "After confirming the dimensions are working, let's train our network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "executionInfo": {
     "elapsed": 1126,
     "status": "ok",
     "timestamp": 1605499373127,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "ZYDQjKTlm4s8"
   },
   "outputs": [],
   "source": [
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1367237,
     "status": "ok",
     "timestamp": 1605500743242,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "_PJ4OVdBm4s8",
    "outputId": "05ac0621-fe5b-4b54-d2d9-75a0a0585444"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "351/351 [==============================] - 41s 118ms/step - loss: 2.5194\n",
      "Epoch 2/30\n",
      "351/351 [==============================] - 43s 122ms/step - loss: 1.7184\n",
      "Epoch 3/30\n",
      "351/351 [==============================] - 44s 126ms/step - loss: 1.4529\n",
      "Epoch 4/30\n",
      "351/351 [==============================] - 45s 127ms/step - loss: 1.3361\n",
      "Epoch 5/30\n",
      "351/351 [==============================] - 44s 126ms/step - loss: 1.2740\n",
      "Epoch 6/30\n",
      "351/351 [==============================] - 45s 128ms/step - loss: 1.2339\n",
      "Epoch 7/30\n",
      "351/351 [==============================] - 44s 126ms/step - loss: 1.2044\n",
      "Epoch 8/30\n",
      "351/351 [==============================] - 44s 126ms/step - loss: 1.1807\n",
      "Epoch 9/30\n",
      "351/351 [==============================] - 44s 126ms/step - loss: 1.1612\n",
      "Epoch 10/30\n",
      "351/351 [==============================] - 45s 127ms/step - loss: 1.1434\n",
      "Epoch 11/30\n",
      "351/351 [==============================] - 45s 127ms/step - loss: 1.1276\n",
      "Epoch 12/30\n",
      "351/351 [==============================] - 44s 126ms/step - loss: 1.1135\n",
      "Epoch 13/30\n",
      "351/351 [==============================] - 45s 129ms/step - loss: 1.1002\n",
      "Epoch 14/30\n",
      "351/351 [==============================] - 44s 126ms/step - loss: 1.0874\n",
      "Epoch 15/30\n",
      "351/351 [==============================] - 44s 126ms/step - loss: 1.0752\n",
      "Epoch 16/30\n",
      "351/351 [==============================] - 44s 127ms/step - loss: 1.0641\n",
      "Epoch 17/30\n",
      "351/351 [==============================] - 45s 128ms/step - loss: 1.0533\n",
      "Epoch 18/30\n",
      "351/351 [==============================] - 45s 127ms/step - loss: 1.0433\n",
      "Epoch 19/30\n",
      "351/351 [==============================] - 44s 126ms/step - loss: 1.0341\n",
      "Epoch 20/30\n",
      "351/351 [==============================] - 45s 129ms/step - loss: 1.0248\n",
      "Epoch 21/30\n",
      "351/351 [==============================] - 44s 126ms/step - loss: 1.0169\n",
      "Epoch 22/30\n",
      "351/351 [==============================] - 44s 126ms/step - loss: 1.0094\n",
      "Epoch 23/30\n",
      "351/351 [==============================] - 44s 127ms/step - loss: 1.0025\n",
      "Epoch 24/30\n",
      "351/351 [==============================] - 45s 128ms/step - loss: 0.9966\n",
      "Epoch 25/30\n",
      "351/351 [==============================] - 45s 127ms/step - loss: 0.9909\n",
      "Epoch 26/30\n",
      "351/351 [==============================] - 44s 126ms/step - loss: 0.9857\n",
      "Epoch 27/30\n",
      "351/351 [==============================] - 45s 129ms/step - loss: 0.9813\n",
      "Epoch 28/30\n",
      "351/351 [==============================] - 44s 126ms/step - loss: 0.9776\n",
      "Epoch 29/30\n",
      "351/351 [==============================] - 45s 127ms/step - loss: 0.9736\n",
      "Epoch 30/30\n",
      "351/351 [==============================] - 45s 127ms/step - loss: 0.9704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe3600b04e0>"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset,epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKkD5M6eoSiN"
   },
   "source": [
    "## Step 6: Generating text\n",
    "\n",
    "Currently our model only expects 128 sequences at a time. We can create a new model that only expects a batch_size=1. We can create a new model with this batch size, then load our saved models weights. Then call .build() on the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 1043,
     "status": "ok",
     "timestamp": 1605500778371,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "eYRNG57Govdc"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/My Drive/project_models/shakespeare_gen.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "executionInfo": {
     "elapsed": 1047,
     "status": "ok",
     "timestamp": 1605500805388,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "GCoJayFS8H4d"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 1452,
     "status": "ok",
     "timestamp": 1605500831574,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "_iXG3VJvEXWM"
   },
   "outputs": [],
   "source": [
    "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n",
    "\n",
    "model.load_weights('/content/drive/My Drive/project_models/shakespeare_gen.h5')\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1061,
     "status": "ok",
     "timestamp": 1605500834581,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "LAX3p7_YEilU",
    "outputId": "8fe0baf9-cd22-4c50-94df-5ecfc435df3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 64)             5376      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1026)           3361176   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 84)             86268     \n",
      "=================================================================\n",
      "Total params: 3,452,820\n",
      "Trainable params: 3,452,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 1086,
     "status": "ok",
     "timestamp": 1605500838413,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "WvuwZBX5Ogfd"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_seed,gen_size=100,temp=1.0):\n",
    "    '''\n",
    "    model: Trained Model to Generate Text\n",
    "    start_seed: Intial Seed text in string form\n",
    "    gen_size: Number of characters to generate\n",
    "\n",
    "    Basic idea behind this function is to take in some seed text, format it so\n",
    "    that it is in the correct shape for our network, then loop the sequence as\n",
    "    we keep adding our own predicted characters. Similar to our work in the RNN\n",
    "    time series problems.\n",
    "    '''\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate = gen_size\n",
    "\n",
    "    # Vecotrizing starting seed text\n",
    "    input_eval = [char_to_ind[s] for s in start_seed]\n",
    "\n",
    "    # Expand to match batch format shape\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty list to hold resulting generated text\n",
    "    text_generated = []\n",
    "\n",
    "    # Temperature effects randomness in our resulting text\n",
    "    # The term is derived from entropy/thermodynamics.\n",
    "    # The temperature is used to effect probability of next characters.\n",
    "    # Higher probability == lesss surprising/ more expected\n",
    "    # Lower temperature == more surprising / less expected\n",
    " \n",
    "    temperature = temp\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "\n",
    "    for i in range(num_generate):\n",
    "        # Generate Predictions\n",
    "        predictions = model(input_eval)\n",
    "\n",
    "        # Remove the batch shape dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # Use a cateogircal disitribution to select the next character\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # Pass the predicted charracter for the next input\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        # Transform back to character letter\n",
    "        text_generated.append(ind_to_char[predicted_id])\n",
    "\n",
    "    return (start_seed + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5470,
     "status": "ok",
     "timestamp": 1605500847254,
     "user": {
      "displayName": "Budhaditya Saha",
      "photoUrl": "",
      "userId": "12665406138180867543"
     },
     "user_tz": -330
    },
    "id": "bS69SG5D5lwd",
    "outputId": "cbe47641-436e-4fe5-c912-795a0661a2b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flower's scalb;\n",
      "    And therefore frame her bosom for a\n",
      "    man's as a scruple of peak treason fithle. She saids, when he is\n",
      "    happy made of his pigeops to the world.\n",
      "  Fal. This inhuman tonts to be.\n",
      "  Bene. She will stand yourself not- late as love by ta'en\n",
      "    Upon this I shed in, he wan so sword.  \n",
      "    This same is she; for highly heart another\n",
      "    Was sweet lovely from the ground, as now I brought it;\n",
      "    With these persisting is his value;\n",
      "    And this right need, what, on vile riding\n",
      "    Gallia? Shall I take it here! I swear\n",
      "    As to commit me they will give use them:\n",
      "    And bidders cannon of the arbour with indeed. Why of the world enjoying!\n",
      "  CLOWN. You are any which, I protest  \n",
      "    And see the glassy general shows, take element to thee withal\n",
      "\n",
      "  PANDARUS. What, ir there to shift?\n",
      "  GONZALO. Dear sir, do good stragge and undone now in the repukes: to\n",
      "    old Timon!\n",
      "     That tert it further; that Polonharr'd you have done.\n",
      "  SECOND GENTLEMAN. My lord, here he my father, so I wil\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,\"flower\",gen_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dff5xCHIeEHO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "00_Generating_Text_with_RNNs.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
